# Imports
from numpy import expand_dims, zeros, ones, vstack, asarray
from numpy.random import randn, randint
from keras.datasets.fashion_mnist import load_data
from keras.optimizers import Adam
from keras.models import Sequential
from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout
import matplotlib.pyplot as plt

# Load and prepare training images
def load_real_samples():
	# Load dataset
	(x_train, _), (_, _) = load_data()

	# Add a third dimension for the graysale channel
	x = expand_dims(x_train, axis = -1)

	# Preprocess the data
	x = x.astype('float32') # Convert the data type to float
	x /= 255.0 # Scale the data to a range between 0 and 1
	
	return x

# Load data
dataset = load_real_samples()

# Function to generate real samples
def generate_real_samples(dataset, n_samples):
	# Choose random portions of the data and add them to the input section of the data
	x_random = randint(0, dataset.shape[0], n_samples)
	x = dataset[x_random]
	y = ones((n_samples, 1)) # Assign all "real" images an output of 1 (for the discriminator model)
	return x, y

# Function to generate points in the latent space (input for the generator model)
def generate_latent_points(latent_dim, n_samples):
	# Generate points
	x_input = randn(latent_dim * n_samples)

	# Reshape them into inputs
	x_input = x_input.reshape(n_samples, latent_dim)
	return x_input

# Function to generate fake images with the generator model
def generate_fake_samples(generator, latent_dim, num_samples):
	# Generate inputs (points in the latent space)
	x_input = generate_latent_points(latent_dim, num_samples)

	# Generate outputs with the generator model
	x = generator.predict(x_input)
	y = zeros((num_samples, 1)) # Assign the images the generator creates a value of 0 ("fake") for the discriminator
	return x, y

# Function to plot the images
def view_images(images, dim = 10):
	# Plot images
	for i in range(dim * dim):
		plt.subplot(dim, dim, 1 + i)
		plt.axis('off')
		plt.imshow(images[i, :, :, 0], cmap = 'gray_r')
	
	plt.show()

# Evaluate the discriminator, plot images, and save the model weights
def view_performance(epoch, generator, discriminator, dataset, latent_dim, n_samples = 100):
	# Create real image samples and evaluate the discriminator model on those samples
	x_real, y_real = generate_real_samples(dataset, n_samples)
	_, real_acc = discriminator.evaluate(x_real, y_real, verbose = 0) # Change the verbose to 1 or 2 for more information

	# Create fake image samples (with the generator) and evaluate the discriminator model on those samples
	x_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)
	_, fake_acc = discriminator.evaluate(x_fake, y_fake, verbose = 0) # Change the verbose to 1 or 2 for more information

	# Display discriminator accuracy
	print(f'\n> Discriminator Accuracy on Real Images: {real_acc * 100} | Discriminator Accuracy on Fake Images: {fake_acc * 100}\n')
	
	# Save a file storing the weights of the generator
	file = 'ClothingGANepoch%03d.h5' % (epoch + 1)
	generator.save(file)

	# View images generated by the generator model
	#view_images(x_fake)

# Initialize latent space size
latent_dim = 100

# Create the discriminator model
input_shape = (28, 28, 1) # Initialize the input shape (the size of an image)
discriminator = Sequential() # Create model

# Hidden layers
discriminator.add(Conv2D(64, (3, 3), strides = (2, 2), padding = 'same', input_shape = input_shape))
discriminator.add(LeakyReLU(alpha = 0.2))
discriminator.add(Dropout(0.4))

discriminator.add(Conv2D(64, (3, 3), strides = (2, 2), padding = 'same'))
discriminator.add(LeakyReLU(alpha = 0.2))
discriminator.add(Dropout(0.4))

# Output layers
discriminator.add(Flatten())
discriminator.add(Dense(1, activation = 'sigmoid')) # 1 output neuron and a sigmoid activation function since the model is a binary classifier (it determines whether an image is real or fake)

opt = Adam(learning_rate = 0.0002, beta_1 = 0.5) # Initialize optimizer with standard values
discriminator.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['binary_accuracy']) # Compile discriminator

# Create the generator model
n_nodes = 128 * 7 * 7 # Set framework for a 7 x 7 image produced in 128 different versions
generator = Sequential()

# Input layers
generator.add(Dense(n_nodes, input_dim = latent_dim))
generator.add(LeakyReLU(alpha = 0.2))
generator.add(Reshape((7, 7, 128))) # Reshape the output into an image that can be passed into a convolutional layer

# Hidden layers
generator.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same')) # Layer to upsample the image to 14 x 14
generator.add(LeakyReLU(alpha = 0.2))

generator.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same')) # Layer to upsample the image to 28 x 28
generator.add(LeakyReLU(alpha = 0.2))

# Output layer
generator.add(Conv2D(1, (7, 7), activation = 'sigmoid', padding = 'same')) # Output layer uses a sigmoid activation function so all outputs are in the range 0 through 1

# Create the complete GAN
discriminator.trainable = False # Make discriminator weights stationary
model = Sequential() # Create model

model.add(generator) # Add the generator model to the GAN
model.add(discriminator) # Add the discriminator model to the GAN

model.compile(loss = 'binary_crossentropy', optimizer = opt) # Compile model

# Initialize hyperparameters
epochs = 100
batch_size = 256
batch_per_epoch = int(dataset.shape[0] / batch_size)
half_batch = int(batch_size / 2)

# Train model
for epoch in range(epochs):
	# Iterate over each batch
	for j in range(batch_per_epoch):
		# Get randomly selected "real" samples and generate "fake" ones
		x_real, y_real = generate_real_samples(dataset, half_batch)
		x_fake, y_fake = generate_fake_samples(generator, latent_dim, half_batch)

		# Create training set for the discriminator and train the discriminator on that dataset
		x, y = vstack((x_real, x_fake)), vstack((y_real, y_fake)) # Stack 128 fake examples and 128 real examples to train the model on
		discriminator_loss, _ = discriminator.train_on_batch(x, y)

		# Create inputs and outputs for the generator model (create points in latent space) and train the model on that data
		x_gan = generate_latent_points(latent_dim, batch_size) # Creat inputs
		y_gan = ones((batch_size, 1)) # Create corresponding labels, but inverted (1 for a fake class instead of 0) so that the weights of the generator are updated to make it better
		generator_loss = model.train_on_batch(x_gan, y_gan)

		# Print the loss of each model on this batch
		print(f'> Epoch: {epoch + 1}, {j + 1}/{batch_per_epoch}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}')

	# View the model's performance every five epochs
	if (epoch + 1) % 5 == 0:
		view_performance(epoch, generator, discriminator, dataset, latent_dim)
